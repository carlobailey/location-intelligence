{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Google Maps with Python\n",
    "\n",
    "[Web scraping](https://en.wikipedia.org/wiki/Web_scraping) is the process of extracting data from web pages using software. There are many [techniques](https://en.wikipedia.org/wiki/Web_scraping#Techniques) to scrape data: computer vision, manual copy and pasting, pattern matching, etc â€“ for this tutorial, we will use [HTML parsing](https://en.wikipedia.org/wiki/Web_scraping#HTML_parsing) with HTTP programming. Given the high costs of downloading large amounts of proprietary data, web scraping is sometimes the only option for small scale research projects. Google maps for example, the defacto mapping and navigation platform (as of 2020/2021), has a monopoly on information about the location of businesses across the globe. To get access to this information is very very costly (problems of monoply rule), therefore scraping the data is one of the only options for students. This tutorial demonstrates how to scrape Google Maps POI (points of interest) data in NYC with Python using the Selenium and Beautiful Soup libraries. \n",
    "\n",
    "The first step is to import all the necessary libraries:\n",
    "- [Requests](https://requests.readthedocs.io/en/master/): a HTTP library for Python\n",
    "- [Selenium](https://www.selenium.dev/selenium/docs/api/py/): a tool for automating web browsing\n",
    "- [BeautfiulSoup](https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser)): a package to parse HTML elements\n",
    "- [Shapely](https://shapely.readthedocs.io/en/stable/manual.html): a library for manipulaitng and analysing geometry\n",
    "- [Geopandas](https://geopandas.org/index.html): similar to pandas with extensions to make it easier to work  with geospatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import re\n",
    "from shapely.geometry import Point\n",
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search requests\n",
    "\n",
    "Every request to google maps usually starts from a location and a search query. This first section involves gathering a list of locations (latitudes & longitudes) and search queries (types of POI) to feed into the base URL below. The base url is the request we send to Google and what we'll get back is a selection of POI (businesses) for that location related to the search category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.google.com/maps/search/{0}/@{1},{2},16z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search locations\n",
    "\n",
    "Any search in Google maps requires a location to search from, typically a latitude and longitude pair. Below we use the centroids of select zipcodes within NYC to use as our search locations. There are only 11 zip codes below but this could easily be scaled to the entire city or country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg.connect(\n",
    "    host=os.environ['aws_db_host'],\n",
    "    port=\"5432\",\n",
    "    user=os.environ['aws_db_u'],\n",
    "    password=os.environ['aws_db_p']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_postgis('''\n",
    "    SELECT \n",
    "        region_id,\n",
    "        geom AS geom\n",
    "    FROM geographies.blockgroups\n",
    "    WHERE (STARTS_WITH(region_id, '36061') OR STARTS_WITH(region_id, '36047')\n",
    "           OR STARTS_WITH(region_id, '36085') OR STARTS_WITH(region_id, '36005')\n",
    "           OR STARTS_WITH(region_id, '36081'))\n",
    "    ''', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = gdf['geom'].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = coords.apply(lambda x: x.x).tolist()\n",
    "ys = coords.apply(lambda x: x.y).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = gdf['region_id'].str[2:5].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Here we outline the search categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = ['Restaurants', 'bakery', 'coffee', 'gym', 'yoga', \n",
    "            'clothing', 'electronics', \n",
    "            'beauty', 'hardware', 'galleries',\n",
    "            'museums', 'Hotels', 'deli', \n",
    "            'liquor', 'bar', 'Groceries', 'Takeout', \n",
    "            'Banks', 'Pharmacies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = ['Restaurants']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending a GET request\n",
    "\n",
    "The next step is to send a request to Google's servers about the information we would like returned. This type of request is called a [GET request](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods) in HTTP programming. \n",
    "\n",
    "Below we'll send a single test request to the servers to see what information we get back. We insert a single lat/lng pair into the **base_url** variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = base_url.format(searches[0], xs[0], ys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The next portion of code starts a selenium web driver (the vehicle that powers automated web browsing) and specifies a few browsing options. Specifically we state the web browser should run *headless*, meaning it should not open up a new browser window, and install a Chrome browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "INFO:WDM:Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "INFO:WDM:Get LATEST driver version for 88.0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "INFO:WDM:Get LATEST driver version for 88.0.4324\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/88.0.4324.96/chromedriver_mac64.zip\n",
      "INFO:WDM:Trying to download new driver from http://chromedriver.storage.googleapis.com/88.0.4324.96/chromedriver_mac64.zip\n",
      "[WDM] - Driver has been saved in cache [/Users/carlo/.wdm/drivers/chromedriver/mac64/88.0.4324.96]\n",
      "INFO:WDM:Driver has been saved in cache [/Users/carlo/.wdm/drivers/chromedriver/mac64/88.0.4324.96]\n"
     ]
    }
   ],
   "source": [
    "delay = 10\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), \n",
    "                           options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Intentionally slowing down\n",
    "\n",
    "Although web scraping is not [illegal](https://twitter.com/OrinKerr/status/1171116153948626944), researchers should be careful when scraping private websites. Not due to legality issues, but due to being blocked by the company you're trying to scrape from. Web scraping tools like Selenium browse pages in light speed, way faster than any human, therefore it is easy for company's servers to spot when individuals are trying to scrape their sites. This next section will introduce a few options to intentionally slow down our browsing. Specifically we tell the driver object to wait until certain conditions have been met before moving forward. Once conditions have been met we download the HTML information returned by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting html\n"
     ]
    }
   ],
   "source": [
    "driver.get(url)\n",
    "try:\n",
    "    # wait for button to be enabled\n",
    "    WebDriverWait(driver, delay).until(\n",
    "        EC.element_to_be_clickable((By.CLASS_NAME, 'section-result'))\n",
    "    )\n",
    "    driver.implicitly_wait(40)\n",
    "    html = driver.find_element_by_tag_name('html').get_attribute('innerHTML')\n",
    "except TimeoutException:\n",
    "    print('Loading took too much time!')\n",
    "else:\n",
    "    print('getting html')\n",
    "    html = driver.page_source\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that we have the HTML data, we feed this into Beautiful Soup for parsing, without having to worry about tripping up Google's servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html)\n",
    "results = soup.find_all('div', {'class': 'section-result'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Let's view one item from the results returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a aria-label=\"Breads Bakery\" class=\"section-result\" data-result-index=\"1\" data-section-id=\"ZXf8if7__or:1\" jsaction=\"pane.resultSection.click;keydown:pane.resultSection.keydown;mouseover:pane.resultSection.in;mouseout:pane.resultSection.out;focus:pane.resultSection.focusin;blur:pane.resultSection.focusout\" jsan=\"t-nqWj9GyoaSo,7.section-result,0.aria-label,0.data-result-index,0.data-section-id,0.role,0.ved,0.tabindex,22.jsaction\" jstcache=\"375\" role=\"button\" tabindex=\"0\" ved=\"1i:4,t:12690,e:3,r:1,p:XoTyX72tFa_X5gLZgYS4Aw:1\"> <div class=\"section-ad-result-ad-banner\" jstcache=\"123\"></div> <div class=\"section-result-content\"> <div class=\"section-result-text-content\" jsan=\"7.section-result-text-content\" jstcache=\"124\"> <div class=\"section-result-header-container\"> <div class=\"section-result-header\" jsan=\"7.section-result-header\" jstcache=\"125\"> <div class=\"section-result-partial-result-justification\" jstcache=\"126\" style=\"display:none\"> <span jstcache=\"127\" style=\"display:none\"> \"<span jstcache=\"128\"></span>\" </span> </div> <div class=\"section-result-title-container\" jsan=\"7.section-result-title-container\" jstcache=\"129\"><h3 class=\"section-result-title\" jsan=\"7.section-result-title\" jstcache=\"130\"><span jstcache=\"131\">Breads Bakery</span><button jstcache=\"132\" style=\"display:none\"></button></h3><div class=\"section-subtitle-extension\" jstcache=\"133\"></div><span class=\"ad-badge\" jstcache=\"134\" style=\"display:none\">Ad</span><span class=\"ad-badge\" jstcache=\"135\" style=\"display:none\">Ad</span><span jstcache=\"136\"><span jstcache=\"137\"><span aria-label=\"  3.7 stars  \" class=\"section-result-rating\" jstcache=\"320\"><span aria-hidden=\"true\" class=\"cards-rating-score\" jsan=\"7.cards-rating-score,0.aria-hidden\" jstcache=\"323\">3.7</span><ol class=\"cards-rating-stars\" jstcache=\"324\"><li class=\"cards-rating-star\" jsinstance=\"0\" jstcache=\"325\"></li><li class=\"cards-rating-star\" jsinstance=\"1\" jstcache=\"325\"></li><li class=\"cards-rating-star\" jsinstance=\"*2\" jstcache=\"325\"></li><li class=\"cards-rating-star cards-rating-star-half\" jstcache=\"326\"></li><li class=\"cards-rating-star cards-rating-star-empty\" jsinstance=\"*0\" jstcache=\"327\"></li></ol></span><span aria-label=\"  11 Reviews  \" class=\"section-result-num-ratings\" jsan=\"7.section-result-num-ratings,0.aria-label\" jstcache=\"321\">(11)</span></span><span jstcache=\"138\" style=\"display:none\"></span></span></div> </div> <div jstcache=\"139\"> <div class=\"section-result-hotel-price\" jsan=\"7.section-result-hotel-price\" jstcache=\"335\" style=\"display:none\"></div> <div class=\"section-result-hotel-price\" jstcache=\"336\" style=\"display:none\"> <div jstcache=\"337\"></div> <div aria-hidden=\"true\" class=\"section-hotel-value-price section-hotel-value-price-enroute\" jsan=\"7.section-hotel-value-price,7.section-hotel-value-price-enroute,0.aria-hidden\" jstcache=\"338\"></div> </div> <div class=\"section-result-hotel-price\" jstcache=\"339\" style=\"display:none\"> <div class=\"section-result-offer-price\" jsan=\"7.section-result-offer-price\" jstcache=\"340\"></div> </div> </div> <div jstcache=\"140\" style=\"display:none\"></div> </div> <div class=\"section-result-details-container\" jsan=\"7.section-result-details-container\" jstcache=\"141\"> <span class=\"ad-badge\" jstcache=\"142\" style=\"display:none\">Ad</span> <span class=\"section-result-cost\" jsan=\"7.section-result-cost,0.role\" jstcache=\"143\" role=\"text\"></span> <span aria-hidden=\"true\" class=\"section-result-separator\" jstcache=\"144\" style=\"display:none\">Â·</span> <span class=\"section-result-details\" jsan=\"7.section-result-details\" jstcache=\"145\">Bakery</span> <span aria-hidden=\"true\" class=\"section-result-separator\" jstcache=\"146\">Â·</span> <span class=\"section-result-location\" jsan=\"7.section-result-location\" jstcache=\"147\">55 Water St</span> </div> <div jstcache=\"148\" style=\"display:none\"> <span class=\"ad-badge\">Ad</span> </div> <div class=\"section-result-descriptions GLOBAL__gm2-body-2 section-result-no-padding-top\" jsan=\"7.section-result-descriptions,7.GLOBAL__gm2-body-2,7.section-result-no-padding-top\" jstcache=\"149\" style=\"display:none\"> <div class=\"section-result-description\" jstcache=\"150\" style=\"display:none\"> <span jstcache=\"151\"></span> </div> </div> <div class=\"section-result-hours-phone-container\" jsan=\"7.section-result-hours-phone-container\" jstcache=\"152\"> <span class=\"section-result-info section-result-closed\" jstcache=\"153\"> <span jstcache=\"154\">Temporarily closed</span> <span aria-hidden=\"true\" class=\"section-result-separator\" jstcache=\"155\" style=\"display:none\">Â·</span> </span> <span class=\"section-result-info section-result-opening-hours\" jstcache=\"156\" style=\"display:none\"> <span jstcache=\"157\"></span> <span aria-hidden=\"true\" class=\"section-result-separator\" jstcache=\"158\" style=\"display:none\">Â·</span> </span> <span class=\"section-result-info section-result-phone-number\" jstcache=\"159\" style=\"display:none\"> <span jstcache=\"160\"></span> <span aria-hidden=\"true\" class=\"section-result-separator\" jstcache=\"161\" style=\"display:none\">Â·</span> </span> <span class=\"section-result-info\" jsan=\"7.section-result-info\" jstcache=\"162\" style=\"display:none\"></span> </div> <jsl jstcache=\"163\"> <div jstcache=\"277\" style=\"display:none\"></div> </jsl> <div class=\"section-hotel-offer-info section-hotel-offer-info-enroute\" jsan=\"7.section-hotel-offer-info,7.section-hotel-offer-info-enroute\" jstcache=\"164\" style=\"display:none\"></div> <div class=\"section-hotel-offer-info section-hotel-offer-info-enroute\" jsan=\"7.section-hotel-offer-info,7.section-hotel-offer-info-enroute\" jstcache=\"165\" style=\"display:none\"></div> <div jstcache=\"166\" style=\"display:none\"></div> <div class=\"section-result-details-container section-result-no-padding-top\" jsan=\"7.section-result-details-container,7.section-result-no-padding-top\" jstcache=\"167\" style=\"display:none\"> <div class=\"section-result-regular-gas-station\"></div> <span class=\"section-result-regular-gas-price\" jsan=\"7.section-result-regular-gas-price\" jstcache=\"168\"></span> <span>/</span> <span jstcache=\"169\"></span> <span jstcache=\"170\" style=\"display:none\">Â *</span> </div> <div class=\"section-result-details-container section-result-no-padding-top\" jsan=\"7.section-result-details-container,7.section-result-no-padding-top\" jstcache=\"171\" style=\"display:none\"> <div class=\"section-result-bikeshare-station\"></div> <span jstcache=\"172\"></span> </div> </div> <div class=\"section-image-container\" jsan=\"7.section-image-container,t-VaTdzLEqzxc\" jstcache=\"173\"> <div class=\"section-result-image\" jsan=\"7.section-result-image,5.background-image,0.ved\" jstcache=\"292\" style=\"background-image:url(https://lh5.googleusercontent.com/p/AF1QipMrwCCviq09bMN22cxdD4t0IgYVF_9vTi52ntqc=w122-h92-k-no)\" ved=\"1i:5,t:25178,e:0,p:XoTyX72tFa_X5gLZgYS4Aw:1\"></div> <div jstcache=\"293\" style=\"display:none\"></div> </div> <div jstcache=\"174\" style=\"display:none\"></div> </div> <div class=\"section-result-subsection-container\" jstcache=\"175\"></div> <div jstcache=\"176\" style=\"display:none\"></div> <div jstcache=\"177\" style=\"display:none\"></div> <div class=\"section-result-internal-place-action\" jstcache=\"178\"></div> <div class=\"section-result-list-ad-banner\" jstcache=\"180\"></div> </a>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "As you can see, there is a ton of information returned but it is not in a human readable format.\n",
    "\n",
    "To interpret this information we will have to go to a page from google maps and understand what our information is represented as in [HTML format](https://www.w3schools.com/whatis/whatis_htmldom.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/img/web_elements.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "Above is an example of a restaurant in Brooklyn as seen from Google maps, alongside the HTML representation. To open up the pop-up, right click anywhere on a page in Google maps and click **inspect elements**. Now hovering over a certain piece of information will tell you what HTML tag, class or ID the element has been assigned. For example, the name of the restaurant above, Park Plaza, is in a **H3** tag inside another **span** tag (highlighted in bliue at the bottom). Now we know the HTML representation, we can more easily parse the data with Beautiful Soup to return the information we want.\n",
    "\n",
    "Below we ask Beatiful Soup to find a H3 tag element and then get the text from the subsequent span element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No. 7'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].find('h3').span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can now scale the above logic to get all the attributes we're interested in (name, address, price, tags, etc.), from all the zip codes, and all the POI categories. We'll wrap the POI parsing in a nested loop and save the results to a CSV using Pandas. We also add Python's built-in **try** and **except** objects to the HTML parsing logic so that the loop continues even when there data is not returned as expected (a common thing in web scraping). At the end of the loop we will delay the next loop by 15 seconds to not trigger Google's servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search in searches:   \n",
    "    for idx, coord in enumerate(zip(ys, xs)):\n",
    "        filename = search + str(coord[0]).replace('.', '') + '_' + str(coord[1]).replace('.', '') + '.csv'\n",
    "        if not os.path.isfile('data/'+filename):\n",
    "            url = base_url.format(search, coord[0], coord[1])\n",
    "            delay = 10\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            driver = webdriver.Chrome('/Users/carlo/.wdm/drivers/chromedriver/mac64/88.0.4324.96/chromedriver', \n",
    "                                       options=chrome_options)\n",
    "            driver.get(url)\n",
    "\n",
    "            try:\n",
    "                # wait for button to be enabled\n",
    "                WebDriverWait(driver, delay).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, 'section-result'))\n",
    "                )\n",
    "                driver.implicitly_wait(10)\n",
    "                html = driver.find_element_by_tag_name('html').get_attribute('innerHTML')\n",
    "            except TimeoutException:\n",
    "                print('Loading took too much time! iteration {0}'.format(idx))\n",
    "                continue\n",
    "            else:\n",
    "                html = driver.page_source\n",
    "            finally:\n",
    "                driver.quit()\n",
    "            soup = BeautifulSoup(html)\n",
    "            results = soup.find_all('div', {'class': 'section-result'})\n",
    "            data = []\n",
    "            for item in results:\n",
    "                try:\n",
    "                    name = item.find('h3').span.text\n",
    "                except:\n",
    "                    name = None\n",
    "                try:\n",
    "                    rating = item.find('span', {'class': 'cards-rating-score'}).text\n",
    "                except:\n",
    "                    rating = None\n",
    "                try:\n",
    "                    num_reviews = item.find('span', {'class': 'section-result-num-ratings'}).text\n",
    "                except:\n",
    "                    num_reviews = None\n",
    "                try:\n",
    "                    cost = item.find('span', {'class': 'section-result-cost'}).text\n",
    "                except:\n",
    "                    cost = None\n",
    "                try:\n",
    "                    tags = item.find('span', {'class': 'section-result-details'}).text\n",
    "                except:\n",
    "                    tags = None\n",
    "                try:\n",
    "                    addr = item.find('span', {'class': 'section-result-location'}).text\n",
    "                except:\n",
    "                    addr = None\n",
    "                try:\n",
    "                    descrip = item.find('div', {'class': 'section-result-description'}).text\n",
    "                except:\n",
    "                    descrip = None\n",
    "                data.append({'name': name, 'rating': rating, 'num_revs': num_reviews,\n",
    "                             'cost': cost, 'tags': tags, 'address': addr, \n",
    "                             'description': descrip, 'county': counties[idx]})\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            temp_df.to_csv('data/' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that we have the scraped results from Google Maps, we merge all the CSVs into a sinlge DataFrame for easier analysis. In addition, we also change the county codes to county names (to help with the later (optional) geocoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "all_files = glob.glob('data' + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, dtype={'county': str})\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.drop('Unnamed: 0', axis=1).drop_duplicates().to_csv('nyc_poi_county.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.drop('Unnamed: 0', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['county'] = frame['county'].replace({'061': 'new york', \n",
    "                                           '081': 'queens', \n",
    "                                           '047': 'brooklyn', \n",
    "                                           '005': 'bronx', \n",
    "                                           '085': 'staten island'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['complete'] = frame['address'] + ' ' + frame['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7752, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_revs</th>\n",
       "      <th>cost</th>\n",
       "      <th>tags</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shabu Shabu Mayumon</td>\n",
       "      <td>4.9</td>\n",
       "      <td>(34)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shabu Shabu</td>\n",
       "      <td>115 Division St</td>\n",
       "      <td>Shabu-shabu omakase counter</td>\n",
       "      <td>new york</td>\n",
       "      <td>115 Division St new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westville</td>\n",
       "      <td>4.4</td>\n",
       "      <td>(607)</td>\n",
       "      <td>$$</td>\n",
       "      <td>American</td>\n",
       "      <td>110 Wall St</td>\n",
       "      <td>Health-conscious American eatery</td>\n",
       "      <td>new york</td>\n",
       "      <td>110 Wall St new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhatta</td>\n",
       "      <td>4.7</td>\n",
       "      <td>(976)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fine Dining</td>\n",
       "      <td>28 Liberty St 60th floor</td>\n",
       "      <td>Upscale New American meals on 60th floor</td>\n",
       "      <td>new york</td>\n",
       "      <td>28 Liberty St 60th floor new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Odeon</td>\n",
       "      <td>4.4</td>\n",
       "      <td>(1,012)</td>\n",
       "      <td>$$$</td>\n",
       "      <td>American</td>\n",
       "      <td>145 W Broadway</td>\n",
       "      <td>French-American fare in bistro setting</td>\n",
       "      <td>new york</td>\n",
       "      <td>145 W Broadway new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Capital Grille</td>\n",
       "      <td>4.6</td>\n",
       "      <td>(1,084)</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>Fine Dining</td>\n",
       "      <td>120 Broadway</td>\n",
       "      <td>Upscale chophouse chain with clubby look</td>\n",
       "      <td>new york</td>\n",
       "      <td>120 Broadway new york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  rating num_revs  cost         tags  \\\n",
       "0  Shabu Shabu Mayumon     4.9     (34)   NaN  Shabu Shabu   \n",
       "1            Westville     4.4    (607)    $$     American   \n",
       "2             Manhatta     4.7    (976)   NaN  Fine Dining   \n",
       "3            The Odeon     4.4  (1,012)   $$$     American   \n",
       "4   The Capital Grille     4.6  (1,084)  $$$$  Fine Dining   \n",
       "\n",
       "                    address                                 description  \\\n",
       "0           115 Division St                Shabu-shabu omakase counter    \n",
       "1               110 Wall St           Health-conscious American eatery    \n",
       "2  28 Liberty St 60th floor   Upscale New American meals on 60th floor    \n",
       "3            145 W Broadway     French-American fare in bistro setting    \n",
       "4              120 Broadway   Upscale chophouse chain with clubby look    \n",
       "\n",
       "     county                           complete  \n",
       "0  new york           115 Division St new york  \n",
       "1  new york               110 Wall St new york  \n",
       "2  new york  28 Liberty St 60th floor new york  \n",
       "3  new york            145 W Broadway new york  \n",
       "4  new york              120 Broadway new york  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(frame.shape)\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End!\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### (optional) Code to Geocode Results\n",
    "\n",
    "The below loop uses the HERE API to geocode the above results to get latitude and longitude for each result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = os.environ['here_app_id']\n",
    "code = os.environ['here_app_code']\n",
    "lats = []\n",
    "lngs = []\n",
    "\n",
    "for idx, address in enumerate(frame['complete']):\n",
    "    try:\n",
    "        search = frame['complete'].iloc[idx]\n",
    "        url = \"https://geocoder.api.here.com/6.2/geocode.json?app_id=%s&app_code=%s&searchtext=%s&country=USA\"\n",
    "        url = url % (app_id, code, search)\n",
    "        r = requests.get(url)\n",
    "        features = r.json()\n",
    "        view = features['Response']['View'][0]\n",
    "        res = view['Result'][0]\n",
    "        loc = res['Location']\n",
    "        pt = loc['DisplayPosition']\n",
    "        lat, lng = pt['Latitude'], pt['Longitude']\n",
    "        lats.append(lat)\n",
    "        lngs.append(lng)\n",
    "    except:\n",
    "        lats.append(None)\n",
    "        lngs.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Finally we add the points to the DataFrame to create a GeoDataFrame and export it as a GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['lat'] = lats\n",
    "frame['lng'] = lngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['coords'] = frame.apply(lambda x: Point([x['lng'], x['lat']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_frame = gpd.GeoDataFrame(frame, geometry='coords', crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7573, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_revs</th>\n",
       "      <th>cost</th>\n",
       "      <th>tags</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>complete</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shabu Shabu Mayumon</td>\n",
       "      <td>4.9</td>\n",
       "      <td>(34)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shabu Shabu</td>\n",
       "      <td>115 Division St</td>\n",
       "      <td>Shabu-shabu omakase counter</td>\n",
       "      <td>new york</td>\n",
       "      <td>115 Division St new york</td>\n",
       "      <td>40.71434</td>\n",
       "      <td>-73.99205</td>\n",
       "      <td>POINT (-73.99205 40.71434)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westville</td>\n",
       "      <td>4.4</td>\n",
       "      <td>(607)</td>\n",
       "      <td>$$</td>\n",
       "      <td>American</td>\n",
       "      <td>110 Wall St</td>\n",
       "      <td>Health-conscious American eatery</td>\n",
       "      <td>new york</td>\n",
       "      <td>110 Wall St new york</td>\n",
       "      <td>40.70478</td>\n",
       "      <td>-74.00652</td>\n",
       "      <td>POINT (-74.00652 40.70478)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhatta</td>\n",
       "      <td>4.7</td>\n",
       "      <td>(976)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fine Dining</td>\n",
       "      <td>28 Liberty St 60th floor</td>\n",
       "      <td>Upscale New American meals on 60th floor</td>\n",
       "      <td>new york</td>\n",
       "      <td>28 Liberty St 60th floor new york</td>\n",
       "      <td>40.70797</td>\n",
       "      <td>-74.00889</td>\n",
       "      <td>POINT (-74.00889 40.70797)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Odeon</td>\n",
       "      <td>4.4</td>\n",
       "      <td>(1,012)</td>\n",
       "      <td>$$$</td>\n",
       "      <td>American</td>\n",
       "      <td>145 W Broadway</td>\n",
       "      <td>French-American fare in bistro setting</td>\n",
       "      <td>new york</td>\n",
       "      <td>145 W Broadway new york</td>\n",
       "      <td>40.71692</td>\n",
       "      <td>-74.00792</td>\n",
       "      <td>POINT (-74.00792 40.71692)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Capital Grille</td>\n",
       "      <td>4.6</td>\n",
       "      <td>(1,084)</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>Fine Dining</td>\n",
       "      <td>120 Broadway</td>\n",
       "      <td>Upscale chophouse chain with clubby look</td>\n",
       "      <td>new york</td>\n",
       "      <td>120 Broadway new york</td>\n",
       "      <td>40.70823</td>\n",
       "      <td>-74.01056</td>\n",
       "      <td>POINT (-74.01056 40.70823)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  rating num_revs  cost         tags  \\\n",
       "0  Shabu Shabu Mayumon     4.9     (34)   NaN  Shabu Shabu   \n",
       "1            Westville     4.4    (607)    $$     American   \n",
       "2             Manhatta     4.7    (976)   NaN  Fine Dining   \n",
       "3            The Odeon     4.4  (1,012)   $$$     American   \n",
       "4   The Capital Grille     4.6  (1,084)  $$$$  Fine Dining   \n",
       "\n",
       "                    address                                 description  \\\n",
       "0           115 Division St                Shabu-shabu omakase counter    \n",
       "1               110 Wall St           Health-conscious American eatery    \n",
       "2  28 Liberty St 60th floor   Upscale New American meals on 60th floor    \n",
       "3            145 W Broadway     French-American fare in bistro setting    \n",
       "4              120 Broadway   Upscale chophouse chain with clubby look    \n",
       "\n",
       "     county                           complete       lat       lng  \\\n",
       "0  new york           115 Division St new york  40.71434 -73.99205   \n",
       "1  new york               110 Wall St new york  40.70478 -74.00652   \n",
       "2  new york  28 Liberty St 60th floor new york  40.70797 -74.00889   \n",
       "3  new york            145 W Broadway new york  40.71692 -74.00792   \n",
       "4  new york              120 Broadway new york  40.70823 -74.01056   \n",
       "\n",
       "                       coords  \n",
       "0  POINT (-73.99205 40.71434)  \n",
       "1  POINT (-74.00652 40.70478)  \n",
       "2  POINT (-74.00889 40.70797)  \n",
       "3  POINT (-74.00792 40.71692)  \n",
       "4  POINT (-74.01056 40.70823)  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gdf_frame.dropna(subset=['lat']).shape)\n",
    "gdf_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_frame.dropna(subset=['lat']).to_file(\"nyc_poi.geojson\", driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
